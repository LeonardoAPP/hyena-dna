{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface import HyenaDNAPreTrainedModel\n",
    "from standalone_hyenadna import CharacterTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = 'hyenadna-large-1m-seqlen'\n",
    "n_classes = 2\n",
    "use_head =  False\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu' # use cuda for models 1k up to 160k sequence length\n",
    "device = 'cpu'  # use cpu for models 450k up to 1m sequence length\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'hyenadna-large-1m-seqlen'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n"
     ]
    }
   ],
   "source": [
    "# when loading a model, the corresponding checkpoint is downloaded from the huggingface model hub\n",
    "model = HyenaDNAPreTrainedModel.from_pretrained(\n",
    "            './checkpoints',\n",
    "            pretrained_model_name,\n",
    "            download = True,\n",
    "            config = None,\n",
    "            device = device,\n",
    "            use_head =  use_head,\n",
    "            n_classes = n_classes,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lengths = {\n",
    "        'hyenadna-tiny-1k-seqlen': 1024,\n",
    "        'hyenadna-small-32k-seqlen': 32768,\n",
    "        'hyenadna-medium-160k-seqlen': 160000,\n",
    "        'hyenadna-medium-450k-seqlen': 450000,  # T4 up to here\n",
    "        'hyenadna-large-1m-seqlen': 1_000_000,  # only A100 (paid tier)\n",
    "    }\n",
    "\n",
    "max_length = max_lengths[pretrained_model_name]  # auto selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = CharacterTokenizer(\n",
    "    characters=['A', 'C', 'G', 'T', 'N'],  # add DNA characters, N is uncertain\n",
    "    model_max_length=max_length + 2,  # to account for special tokens, like EOS\n",
    "    add_special_tokens=False,  # we handle special tokens elsewhere\n",
    "    padding_side='left', # since HyenaDNA is causal, we pad on the left\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Single embedding example ####\n",
    "\n",
    "# create a sample 450k long, prepare\n",
    "sequence = 'ACTG' * int(max_length/4)\n",
    "tok_seq = tokenizer(sequence)\n",
    "tok_seq = tok_seq[\"input_ids\"]  # grab ids\n",
    "\n",
    "# place on device, convert to tensor\n",
    "tok_seq = torch.LongTensor(tok_seq).unsqueeze(0)  # unsqueeze for batch dim\n",
    "tok_seq = tok_seq.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000002, 256])\n"
     ]
    }
   ],
   "source": [
    "# prep model and forward\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    embeddings = model(tok_seq)\n",
    "\n",
    "print(embeddings.shape)  # embeddings here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyena-dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
